{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTeaOXW5RBvQ+wxPdayrIJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jazaineam1/bayesiana/blob/main/Cuadernos/Bayes_2_(F_a_priori_y_a_posteriori).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-Zib0BIiEIU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distribución \"A Priori\": Una Introducción\n",
        "\n",
        "En estadística bayesiana, una distribución \"a priori\" representa las creencias o conocimientos previos acerca de un parámetro antes de observar los datos. Esta distribución forma la base del análisis bayesiano y se combina con los datos observados para formar una distribución \"a posteriori\", que refleja las creencias actualizadas sobre el parámetro tras considerar la nueva evidencia.\n",
        "\n",
        "El análisis estadístico se fundamenta en el concepto de probabilidad. Su definición matemática es específica: se refiere a una función aditiva no negativa que alcanza como valor máximo la unidad. Sin embargo, la principal complicación surge al determinar cómo se establece esta función. Ashby discute que las distribuciones \"a priori\" pueden interpretarse de tres maneras diferentes: pueden basarse en frecuencias obtenidas de datos anteriores, representar de manera objetiva lo que se considera racional asumir sobre un parámetro, o bien, reflejar la medida subjetiva de creencia de un individuo en particular.\n",
        "\n",
        "#### Clasificación de las Distribuciones \"A Priori\"\n",
        "\n",
        "Las distribuciones \"a priori\" se dividen en distintos tipos:\n",
        "\n",
        "1. **Propias vs. Impropias**:\n",
        "   - **Propias**: Son aquellas que asignan pesos no negativos a todos los posibles valores del parámetro y cuya suma o integración es igual a uno. Cumplen con los requisitos de una función de densidad de probabilidad.\n",
        "   - **Impropias**: Son aquellas cuya suma o integración resulta en un valor distinto de uno, denominado K. Si K es finito, se puede obtener una distribución propia a través de la normalización de la función. Si K es infinito, la distribución se usa como una herramienta de ponderación o técnica para derivar una distribución posterior.\n",
        "\n",
        "2. **Informativas vs. No Informativas**:\n",
        "   - **No Informativas**: Son aquellas que expresan una total ignorancia o un conocimiento muy limitado acerca del parámetro de interés. Su objetivo es reflejar una posición neutral ante la información previa.\n",
        "   \n",
        "3. **Conjugadas vs. No Conjugadas**:\n",
        "   - **Conjugadas**: Se dice que una distribución \"a priori\" es conjugada cuando, después de actualizarla con datos muestrales, la distribución \"a posteriori\" mantiene la misma forma que la \"a priori\", cambiando solo en los hiperparámetros, es decir, en parámetros diferentes a los del modelo muestral.\n",
        "\n",
        "Estas clasificaciones permiten a los estadísticos y a los investigadores escoger la distribución \"a priori\" más adecuada según el conocimiento previo y la información disponible, lo que a su vez influye en la interpretación y los resultados del análisis bayesiano."
      ],
      "metadata": {
        "id": "NOWzrRLYxatH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2sKGfI8txbUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análisis Preposterior en Estadística Bayesiana\n",
        "\n",
        "En el contexto de la estadística bayesiana, el análisis preposterior es una etapa crítica donde evaluamos la robustez y la idoneidad de nuestras creencias previas (a priori) antes de observar los datos. Este análisis ayuda a asegurar un razonamiento bayesiano sólido y fundamentado. Martz y Waller destacan varios pasos cruciales para realizar un análisis bayesiano eficaz:\n",
        "\n",
        "1. **Justificación y Análisis de la Distribución \"A Priori\"**: Es esencial justificar la elección de la distribución a priori seleccionada, comprendiendo plenamente sus implicaciones matemáticas. Por ejemplo, optar por una distribución normal para representar conocimiento previo nos limita a distribuciones que son unimodales.\n",
        "\n",
        "2. **Documentación de Fuentes de Datos**: Las fuentes utilizadas para determinar la distribución a priori deben documentarse exhaustivamente. Esto añade transparencia y credibilidad al análisis.\n",
        "\n",
        "3. **Realización de Análisis Preposterior**: Este paso implica evaluar la distribución a priori con escenarios de prueba hipotéticos para comprobar su calidad. Esto puede incluir generar muestras bajo diferentes condiciones y verificar si los resultados son coherentes con las expectativas.\n",
        "\n",
        "4. **Definición de la Distribución \"A Posteriori\"**: Se debe establecer claramente cómo se actualizarán las creencias a priori en función de los nuevos datos para formar la distribución a posteriori.\n",
        "\n",
        "5. **Análisis de Sensibilidad**: Se deben analizar las inferencias bayesianas para variaciones en la distribución a priori elegida, lo que ayuda a entender el impacto de las suposiciones previas en los resultados finales.\n",
        "\n",
        "Durante la elicitación de la distribución a priori, se alienta a los expertos a proporcionar información, pero también deben recibir retroalimentación inmediata para ajustar cualquier desviación notable. Este diálogo garantiza que las distribuciones a priori reflejen con precisión el conocimiento o las creencias previas.\n",
        "\n",
        "Es crucial documentar detalladamente todo el proceso de elicitación, incluyendo justificaciones para la relevancia de datos o estudios anteriores al problema actual. Por ejemplo, un estudio sobre el consumo de drogas en una ciudad puede no ser aplicable directamente a otra ciudad, aunque puede haber excepciones en casos de fenómenos biológicos más generales.\n",
        "\n",
        "La elección de la distribución a priori puede variar en método y complejidad. Es recomendable emplear múltiples métodos de elicitación para garantizar la consistencia entre las distribuciones a priori deducidas de diferentes maneras.\n",
        "\n",
        "Finalmente, el análisis preposterior verifica la fiabilidad de las creencias a priori. Este paso es análogo a un análisis exploratorio de datos, donde se investigan las características y posibles problemas de la distribución a priori propuesta. Este análisis ayuda a determinar si la distribución es creíble, computacionalmente viable, y bien definida sobre el espacio de parámetros, y si es robusta ante la adquisición de nuevos datos.\n",
        "\n",
        "En situaciones donde existen diferencias significativas entre múltiples distribuciones a priori, ya sea por distintos expertos o métodos de elicitación, puede ser prudente considerar y trabajar con varias distribuciones a priori en el análisis, aprovechando la disponibilidad de recursos computacionales modernos para manejar múltiples escenarios."
      ],
      "metadata": {
        "id": "WjykGTwry3_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distribución Predictiva A Priori\n",
        "\n",
        "La construcción de la distribución predictiva a priori es fundamental en la estadística bayesiana para evaluar la calidad de una distribución a priori elicitada. Esta distribución combina el conocimiento previo sobre el parámetro de interés, $θ$, expresado a través de la distribución a priori $ξ(θ)$, con el modelo de los datos, $f(y|θ)$, para predecir posibles resultados futuros.\n",
        "\n",
        "La fórmula\n",
        "$$ p(y) = ∫ f(y|θ) ξ(θ) dθ $$ define cómo se calcula la distribución predictiva a priori, integrando sobre todos los posibles valores de $θ$. Si los resultados predichos por esta distribución están en línea con las expectativas del analista, esto sugiere que la distribución a priori es apropiada y se puede avanzar en el análisis.\n",
        "\n",
        "Este enfoque también permite probar la robustez de las conclusiones cambiando la distribución a priori. Sin embargo, es importante notar que este método no es aplicable a distribuciones a priori no informativas debido a la falta de conocimiento previo específico.\n",
        "\n",
        "Como ejemplo práctico, consideremos el análisis de los goles marcados en partidos de fútbol profesional en Colombia. Si un experto sugiere que el número promedio de goles, $θ$, sigue una distribución normal $N(2.5, (0.20)^2)$, y asumimos que el número de goles por partido sigue una distribución de $Poisson(θ)$, entonces se puede calcular la distribución predictiva a priori correspondiente para validar nuestras creencias previas y proceder con el análisis posterior basado en estas asunciones.\n",
        "\n",
        "\n",
        "$$p(y) = \\int_{0}^{\\infty} \\frac{\\theta^{y} \\exp(-\\theta)}{y!} \\frac{1}{\\sqrt{2\\pi} 0.20} \\exp\\left(-\\frac{1}{2 \\times 0.2^2}(\\theta - 2.5)^2\\right) d\\theta$$\n"
      ],
      "metadata": {
        "id": "vjlXcLUWzs3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulación de la Distribución Predictiva a priori\n",
        "# Nro. promedio de goles del campeonato colombiano\n",
        "# A priori: Normal(2.5, 0.20^2)\n",
        "# Dist. muestral: Poisson(theta)\n",
        "# función que muestrea de la predictiva\n",
        "dist.predictiva<-function(Nsim=10000,media=2.5,dt=0.20){\n",
        "    # genera valores de la Poisson con parámetros de la normal\n",
        "    res<-rpois(Nsim,rnorm(Nsim,mean=media,sd=dt))\n",
        "    # tabla de frecuencias para los valores generados\n",
        "    tabla<-table(res)\n",
        "    print(tabla/sum(tabla))\n",
        "    barplot(tabla) # diagrama de barras para valores generados\n",
        "    print(summary(res)) # resumen estadístico\n",
        "    print(var(res))\n",
        "} # fin de la función\n",
        "dist.predictiva()\n",
        "title(main=\"Distribución predictiva\\n campeonato colombiano\",xlab=\"Número de Goles\", ylab=\"Frecuencia\")\n",
        "legend(7,2000,c(\"Media a priori=2.5\",\"Desv. Est. a priori=0.20\"),bty=\"n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "id": "z0O0VOSK0whs",
        "outputId": "b2bda440-0c85-4025-e602-fd0c6caf592c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "res\n",
            "     0      1      2      3      4      5      6      7      8      9     10 \n",
            "0.0844 0.2069 0.2537 0.2122 0.1315 0.0652 0.0315 0.0095 0.0037 0.0008 0.0005 \n",
            "    11 \n",
            "0.0001 \n",
            "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
            "  0.000   1.000   2.000   2.501   3.000  11.000 \n",
            "[1] 2.572456\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Plot with title “Distribución predictiva\n",
              " campeonato colombiano”"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAADAFBMVEUAAAABAQECAgIDAwME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"
          },
          "metadata": {
            "image/png": {
              "width": 420,
              "height": 420
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A priori, notamos que la mediana del número de goles para un nuevo partido del\n",
        "rentado colombiano sería de 2 goles.\n"
      ],
      "metadata": {
        "id": "QBtutfnS1WvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El Teorema de Bayes se ha convertido en un pilar fundamental en el campo de la estadística, generando debates no solo acerca de sus orígenes sino también de sus implicaciones filosóficas. Este teorema fue publicado post mortem del reverendo Thomas Bayes por un amigo cercano.\n",
        "\n",
        "## Teorema de Bayes\n",
        "\n",
        "Considerando $B_1, B_2, \\ldots, B_k$ como eventos mutuamente excluyentes y colectivamente exhaustivos, y un evento adicional $A$, el Teorema de Bayes establece que:\n",
        "\n",
        "$$\n",
        "P(B_i | A) = \\frac{P(B_i \\cap A)}{P(A)} = \\frac{P(A | B_i) P(B_i)}{\\sum_{i=1}^{k} P(A | B_i) P(B_i)}\n",
        "$$\n",
        "\n",
        "siempre y cuando $P(A) \\neq 0$ y $P(B_i) \\neq 0$ para $i = 1, 2, \\ldots, k$.\n",
        "\n",
        "## Teorema de Bayes para Variables Aleatorias\n",
        "\n",
        "En el contexto de variables aleatorias $X$ y $\\theta$ con funciones de densidad de probabilidad $f(x|\\theta)$ y $\\xi(\\theta)$ respectivamente, el Teorema de Bayes se expresa como:\n",
        "\n",
        "$$\n",
        "\\xi(\\theta | x) = \\frac{f(x | \\theta) \\xi(\\theta)}{\\int_{\\Theta} f(x | \\theta) \\xi(\\theta) d\\theta}\n",
        "$$\n",
        "\n",
        "Bajo el paradigma bayesiano, donde $X$ representa los datos (pueden ser escalares, vectores o matrices) y $\\theta$ el parámetro desconocido, la inferencia bayesiana surge de la distribución posterior $\\xi(\\theta | x_1, \\ldots, x_n)$, que se define como:\n",
        "\n",
        "$$\n",
        "\\xi(\\theta | x_1, \\ldots, x_n) = \\frac{f(x_1, \\ldots, x_n | \\theta) \\xi(\\theta)}{\\int_{\\Theta} f(x_1, \\ldots, x_n | \\theta) \\xi(\\theta) d\\theta}\n",
        "$$\n",
        "\n",
        "En la práctica, el denominador de la expresión anterior generalmente no necesita calcularse de manera explícita, y la regla de Bayes puede simplificarse a:\n",
        "\n",
        "$$\n",
        "\\xi(\\theta | x_1, \\ldots, x_n) \\propto f(x_1, \\ldots, x_n | \\theta) \\xi(\\theta)\n",
        "$$\n",
        "\n",
        "Esto significa que la distribución posterior de $\\theta$ se puede determinar hasta una constante de normalización, permitiendo una actualización de $\\xi(\\theta)$ a $\\xi(\\theta | x_1, \\ldots, x_n)$ con la adquisición de nuevos datos.\n",
        "\n",
        "## Aprendizaje Bayesiano\n",
        "\n",
        "El teorema de Bayes facilita un mecanismo para actualizar continuamente nuestro conocimiento sobre $\\theta$ conforme se recopilan nuevos datos, mostrando cómo el aprendizaje bayesiano incorpora de forma secuencial la evidencia para modificar nuestra comprensión sobre el estado de la naturaleza."
      ],
      "metadata": {
        "id": "xT9eidEg6yc1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo de Distribución A Priori Uniforme Truncada\n",
        "\n",
        "Al enfrentarnos a un problema binomial, a menudo podemos especificar con claridad las regiones donde es imposible encontrar el parámetro, aunque no podamos precisar más allá nuestro conocimiento sobre este. Una solución es emplear una distribución a priori que refleje esta incertidumbre mediante una distribución uniforme truncada, la cual se define como $\\pi \\sim U(\\pi_0, \\pi_1)$. Esto implica que:\n",
        "\n",
        "$$\n",
        "\\xi (\\pi|\\pi_0, \\pi_1) = \\frac{1}{\\pi_1 - \\pi_0}, \\quad 0 \\leq \\pi_0 < \\pi < \\pi_1 \\leq 1\n",
        "$$\n",
        "\n",
        "La distribución posterior de $\\pi$, dado $x = (x_1, x_2, \\ldots, x_n)$, es calculada por:\n",
        "\n",
        "$$\n",
        "\\xi (\\pi|x, \\pi_0, \\pi_1) = \\frac{\\Gamma(n+2)}{\\Gamma(y+1)\\Gamma(n-y+1)}\\pi^{(y+1)-1}(1 - \\pi)^{(n-y+1)-1} \\left/ \\int_{\\pi_0}^{\\pi_1} \\frac{\\Gamma(n+2)}{\\Gamma(y+1)\\Gamma(n-y+1)}\\pi^{(y+1)-1}(1 - \\pi)^{(n-y+1)-1}d\\pi \\right.\n",
        "$$\n",
        "\n",
        "donde $y = \\sum_{i=1}^{n} x_i$.\n",
        "\n",
        "El denominador de esta función corresponde a $P(\\pi_0 < W < \\pi_1|y + 1, n - y + 1)$, donde $W \\sim Beta(y + 1, n - y + 1)$. Este valor puede calcularse fácilmente en programas como R. La media y la varianza a posteriori se encuentran de manera directa, siendo:\n",
        "\n",
        "$\n",
        "E (\\pi|x, \\pi_0, \\pi_1) = \\frac{y + 1}{n + 2} \\frac{P (\\pi_0 < W < \\pi_1|y + 2, n - y + 1)}{P (\\pi_0 < W < \\pi_1|y + 1, n - y + 1)}\n",
        "$\n",
        "\n",
        "$\n",
        "V ar (\\pi|x, \\pi_0, \\pi_1) = \\frac{(y + 2)(y + 1)}{(n + 3)(n + 2)} \\frac{P (\\pi_0 < W < \\pi_1|y + 3, n - y + 1)}{P (\\pi_0 < W < \\pi_1|y + 1, n - y + 1)} - \\left(\\frac{(y + 1)}{(n + 2)} \\frac{P (\\pi_0 < W < \\pi_1|y + 2, n - y + 1)}{P (\\pi_0 < W < \\pi_1|y + 1, n - y + 1)}\\right)^2\n",
        "$\n",
        "\n",
        "### Ejemplo 4.2: Aplicación Numérica con Distribución A Priori Uniforme Truncada\n",
        "\n",
        "Imaginemos que estimamos que el porcentaje de mujeres estudiando actualmente en una universidad específica se encuentra entre el 35% y el 70%. Para representar esta incertidumbre inicial, optamos por una distribución a priori uniforme truncada, definida como:\n",
        "$$\n",
        "\\xi(\\pi) = \\frac{1}{0.70 - 0.35} \\quad \\text{para} \\quad \\pi \\in (0.35, 0.70), \\quad \\text{y} \\quad 0 \\quad \\text{en cualquier otro caso}.\n",
        "$$\n",
        "\n",
        "Posteriormente, al seleccionar una muestra aleatoria de 10 estudiantes, descubrimos que 4 son mujeres y 6 son hombres, es decir, $y = 4$ y $n = 10$. A pesar del reducido tamaño de la muestra, aplicamos el intervalo de confianza clásico basado en el teorema central del límite, considerando la casi simetría de la distribución poblacional, lo cual nos lleva a:\n",
        "$$\n",
        "\\hat{\\pi} \\pm 1.96\\sqrt{\\frac{\\hat{\\pi}(1 - \\hat{\\pi})}{n}},\n",
        "$$\n",
        "resultando en un intervalo de confianza del 95% de (0.0963, 0.704).\n",
        "\n",
        "Adoptando una aproximación bayesiana, obtenemos la siguiente distribución posterior:\n",
        "$$\n",
        "\\xi (\\pi|n = 10, y = 4, \\pi_0 = 0.35, \\pi_1 = 0.70) = \\frac{\\Gamma(12)}{\\Gamma(5)\\Gamma(5)}\\pi^{4}(1 - \\pi)^{6} \\left/ \\left( K(0.70 ; 5 , 7) - K(0.35 ; 5 , 7) \\right) \\right.,\n",
        "$$\n",
        "donde $K(z; \\alpha, \\beta)$ se calcula como:\n",
        "$$\n",
        "K(z; \\alpha, \\beta) = \\int_{0}^{z} \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} x^{\\alpha-1}(1 - x)^{\\beta-1}dx.\n",
        "$$\n",
        "\n",
        "De este modo, la media a posteriori, $E (\\pi|n = 10, y = 4, \\pi_0 = 0.35, \\pi_1 = 0.70)$, es 0.4823673, y el intervalo de credibilidad del 95% se sitúa entre (0.3561442, 0.6680237). Este intervalo se determina resolviendo la integral:\n",
        "$$\n",
        "\\int_{\\pi_*}^{\\pi^*} \\frac{\\Gamma(12)}{\\Gamma(5)\\Gamma(5)}\\pi^{4}(1 - \\pi)^{6} d\\pi = 0.95,\n",
        "$$\n",
        "y estableciendo el intervalo $(\\pi_*, \\pi^*)$. Este resultado actualiza nuestra creencia inicial, proporcionando un intervalo más preciso en comparación con el estimado inicialmente."
      ],
      "metadata": {
        "id": "LTfLFQza9bXP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distribuciones conjugadas\n",
        "\n",
        "Ante la complejidad de elegir una distribución a priori que refleje con claridad nuestro conocimiento bayesiano, surge de forma natural la idea de enfocar la búsqueda en familias de distribuciones a priori con características particulares:\n",
        "\n",
        "1. **Tratabilidad Analítica**:\n",
        "   a) Que permita determinar fácilmente tanto la distribución posterior basada en la muestra como la distribución a priori.\n",
        "   b) Que facilite la obtención de medidas de interés, como los valores esperados.\n",
        "   c) Que asegure que tanto la distribución a priori como la posterior pertenezcan a la misma familia de distribuciones, formando un conjunto cerrado.\n",
        "\n",
        "2. **Flexibilidad y Riqueza**: Capaz de modelar una amplia gama de conocimientos previos y creencias.\n",
        "\n",
        "3. **Interpretación Intuitiva**: Los parámetros deben ser fácilmente comprensibles para el analista, permitiendo una conexión directa con sus creencias e información previa.\n",
        "\n",
        "Dickey resaltó este proceso de selección de a prioris adecuadas como la búsqueda de distribuciones a priori operacionales o subrogadas. También se discute el concepto de distribuciones a posteriori operacionales.\n",
        "\n",
        "Raiffa y Schlaifer, en 1961, dieron forma al concepto de familias conjugadas. La creación de una familia conjugada depende de identificar estadísticos suficientes de dimensión finita para una determinada función de verosimilitud. La presencia de estos estadísticos permite reducir la dimensionalidad del análisis. Así, cuando estos estadísticos existen, también existe una familia conjugada correspondiente.\n",
        "\n",
        "Una **distribución a priori conjugada natural** se caracteriza por compartir la misma forma funcional que la función de verosimilitud, lo que implica que la información a priori puede interpretarse de la misma forma que los datos en la función de verosimilitud. Es decir, la a priori puede considerarse como si procediera de un conjunto de datos ficticios generados por el mismo proceso que produjo los datos reales.\n",
        "\n",
        "Las distribuciones conjugadas desempeñan un rol crucial en los métodos bayesianos, simplificando el proceso de integración necesario para la marginalización. Esta simplificación resulta de que tanto la a priori como la posterior pertenezcan a la misma familia, facilitando la actualización de parámetros, una gran ventaja para los sistemas inteligentes.\n",
        "\n",
        "No obstante, la conjugación restringe la selección a un conjunto limitado de a prioris, y la información previa se utiliza principalmente para definir hiperparámetros. Aunque esto puede parecer restrictivo, la amplia variedad de clases disponibles suele ser suficiente para muchos casos de uso. Robert señala que esta automatización en la selección de la a priori es tanto una ventaja como una desventaja, ya que, si bien simplifica el proceso de actualización (especialmente en contextos dinámicos), a menudo limita la capacidad de representar adecuadamente la distribución a priori. Un experimento de Diaconis y Ylvisaker ilustra este punto, mostrando cómo la experiencia de lanzar una moneda en posición vertical y que cae sobre una superficie plana sugiere una distribución bimodal, con modas en 1/3 y 2/3, un fenómeno que podría no capturarse adecuadamente mediante el uso exclusivo de distribuciones conjugadas."
      ],
      "metadata": {
        "id": "b-8YSf73BIiL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si consideramos $x_1, ..., x_n$ como variables aleatorias independientes e idénticamente distribuidas (i.i.d.) de un proceso definido por la función $f(x|\\theta)$, donde $\\theta$ representa un conjunto de parámetros desconocidos de interés que pueden ser tanto escalares como vectores, y suponemos la existencia de una familia conjugada para este proceso, denotada por $\\xi(\\theta|\\phi)$, cuyos elementos se indexan mediante el hiperparámetro $\\phi$. La presencia de esta familia conjugada nos permite descomponer la función de verosimilitud $L(\\theta|x_1, ..., x_n)$ de la forma:\n",
        "\n",
        "$$L(\\theta|x_1, ..., x_n) = u(x_1, ..., x_n) v(T(x_1, ..., x_n), \\theta),$$\n",
        "\n",
        "donde $u(\\cdot)$ es una función que no depende de $\\theta$ y $v(T(x_1, ..., x_n), \\theta)$ es una función que involucra tanto al estadístico suficiente como al conjunto de parámetros $\\theta$.\n",
        "\n",
        "Ahora, si nos interesamos en aplicar una transformación biyectiva a los datos, tal que $y_i = h(x_i)$ para $i=1, ..., n$, donde $h(x)$ es biyectiva y, por tanto, tiene una función inversa $h^{-1}(x)$, en el contexto de un proceso continuo, la función de verosimilitud transformada se expresa como:\n",
        "\n",
        "$$L(\\theta|y) = f(h^{-1}(y)|\\theta) \\frac{d}{dy} h^{-1}(y),$$\n",
        "\n",
        "y para el conjunto completo de datos transformados, la función de verosimilitud es:\n",
        "\n",
        "$$L(\\theta|y_1, ..., y_n) = f(h^{-1}(y_1), ..., h^{-1}(y_n)|\\theta) |J|,$$\n",
        "\n",
        "donde $J$ es el jacobiano de la transformación, y se define como:\n",
        "\n",
        "$$J = \\prod_{i=1}^{n} \\frac{d}{dy_i} h^{-1}(y_i).$$\n",
        "\n",
        "Este enfoque nos permite manejar la verosimilitud de los datos transformados de manera que se conserve la estructura de la función de verosimilitud original, aprovechando las propiedades de las familias conjugadas para simplificar el análisis y la interpretación de los parámetros $\\theta$ a través de transformaciones biyectivas de los datos."
      ],
      "metadata": {
        "id": "NRfxjXxfBoKW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La función de verosimilitud para datos transformados se define como:\n",
        "\n",
        "$$L(\\theta|y_1, \\ldots, y_n) = u(h^{-1}(y_1), \\ldots, h^{-1}(y_n)) \\times v(T(h^{-1}(y_1), \\ldots, h^{-1}(y_n)), \\theta) \\times |J|$$\n",
        "\n",
        "Aquí, $|J|$ representa el jacobiano de la transformación, el cual es una función de las $x_i$, y nos da:\n",
        "\n",
        "$$\\mu(x_1, \\ldots, x_n) = u(x_1, \\ldots, x_n) \\times |J|$$\n",
        "\n",
        "Por consiguiente, la función de verosimilitud transformada se puede expresar como:\n",
        "\n",
        "$$L(\\theta|y_1, \\ldots, y_n) = \\mu(x_1, \\ldots, x_n) \\times v(T(x_1, \\ldots, x_n), \\theta)$$\n",
        "\n",
        "Esta representación de la verosimilitud transformada combina una función que solo depende de los datos, que no interactúa directamente con el parámetro, y el núcleo de la verosimilitud original sin transformar. Esto implica que la distribución a priori conjugada para el proceso no transformado permanece igual en el proceso transformado.\n",
        "\n",
        "En las siguientes secciones, examinaremos las distribuciones conjugadas para distintos modelos de probabilidad, ilustrando su aplicación con ejemplos basados en datos reales."
      ],
      "metadata": {
        "id": "w4_KhQn7CIZr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distribución Binomial\n",
        "\n",
        "**Teorema 5.1:** Considere $X_1, ..., X_n$ como una muestra aleatoria de una distribución Bernoulli con parámetro $\\pi$, cuyo valor es desconocido. Supongamos además que la distribución a priori de $\\pi$ es una Beta con parámetros $\\alpha (> 0)$ y $\\beta (> 0)$. Entonces, la distribución posterior de $\\pi$ dado que $X_i = x_i$ para $i = 1, ..., n$, se modela como una distribución Beta con parámetros $\\alpha + \\sum_{i=1}^{n} x_i$ y $\\beta + n - \\sum_{i=1}^{n} x_i$.\n",
        "\n",
        "Las variables $X_1, ..., X_n$ son independientes y siguen una distribución Bernoulli($\\pi$). La función de verosimilitud se expresa como:\n",
        "\n",
        "$$L(\\pi) \\propto \\pi^{\\sum_i X_i} (1 - \\pi)^{n - \\sum_i X_i}$$\n",
        "\n",
        "Aquí, el parámetro $\\pi$ está confinado al intervalo [0, 1]. La distribución conjugada para $\\pi$ se define como:\n",
        "\n",
        "$$\\xi(\\pi) \\propto \\pi^{\\alpha - 1}(1 - \\pi)^{\\beta - 1}$$\n",
        "\n",
        "Donde $\\alpha$ y $\\beta$ son denominados hiperparámetros, diferenciándolos del parámetro del modelo muestral $\\pi$. La comparación entre la distribución a priori y la verosimilitud sugiere que $\\alpha - 1$ puede asociarse con $\\sum_i X_i$ y $\\beta - 1$ con $n - \\sum_i X_i$. Así, el experto que forma su opinión a priori puede conceptualizar esto como extraer una muestra hipotética de ceros y unos de un tamaño total de $\\alpha + \\beta - 2$, repartiéndolos según sus creencias previas. Este ejercicio mental refleja el grado de confianza del experto en sus propias estimaciones previas.\n",
        "\n",
        "Estas ideas previas se resumen a través de los indicadores estadísticos de la distribución Beta:\n",
        "\n",
        "- **Media a priori**: $E(\\pi) = \\frac{\\alpha}{\\alpha + \\beta}$\n",
        "- **Moda**: $\\frac{\\alpha - 1}{\\alpha + \\beta - 2}$\n",
        "- **Varianza**: $\\frac{\\alpha\\beta}{(\\alpha + \\beta)^2(\\alpha + \\beta + 1)} = E(\\pi)(1 - E(\\pi)) / (\\alpha + \\beta + 1)$\n",
        "\n",
        "La esperanza a priori $E(\\pi)$ simboliza la probabilidad agregada de éxito antes de cualquier observación real:\n",
        "\n",
        "$$E(\\pi) = \\int \\pi \\xi(\\pi) d\\pi = \\int p(Y = 1|\\pi) \\xi(\\pi) d\\pi = p(X = 1)\\]\n",
        "\n",
        "La varianza de $\\pi$ disminuye con mayores valores de $\\alpha + \\beta$ manteniendo constante la media, por lo que la suma $\\alpha + \\beta$ se conoce como la 'precisión' de la distribución.\n",
        "\n",
        "Finalmente, la **distribución posterior**:\n",
        "\n",
        "$$\\xi(\\pi|X_1, ..., X_n) \\propto \\pi^{\\alpha + \\sum_i X_i - 1} (1 - \\pi)^{\\beta + n - \\sum_i X_i - 1}$$\n",
        "\n",
        "Es otra distribución Beta pero con hiperparámetros actualizados: $\\alpha + \\sum_i X_i$ y $\\beta + n - \\sum_i X_i$. La precisión posterior, por ende, se incrementa por el tamaño de la muestra $n$.\n",
        "\n",
        "La **media a posteriori** se convierte en una combinación ponderada:\n",
        "\n",
        "$$E(\\pi|X_1, ..., X_n, \\alpha, \\beta) = w \\cdot E(\\pi|\\alpha, \\beta) + (1 - w) \\cdot \\frac{\\sum_{i=1}^{n} X_i}{n}$$\n",
        "\n",
        "donde $w = \\frac{\\alpha + \\beta}{\\alpha + \\beta + n}$, integrando tanto conocimientos previos como nuevos datos observados."
      ],
      "metadata": {
        "id": "XPkg_mmrCtxd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w-EAnW5ny50C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}